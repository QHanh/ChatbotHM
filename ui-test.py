import streamlit as st
import requests
import json
import uuid
import os
from dotenv import load_dotenv

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# --- Responsive & Safari-friendly UI ---
st.set_page_config(page_title="Chatbot B√°n H√†ng", page_icon="ü§ñ", layout="wide")

# safari_friendly_css = """
# <style>
# /* Safari iOS fix input b·ªã che */
# html, body {
#     height: 100%;
#     overflow-x: hidden;
#     -webkit-overflow-scrolling: touch;
#     position: relative;
# }

# .block-container {
#     display: flex;
#     flex-direction: column;
#     height: 100%;
#     padding-bottom: 180px !important; /* TƒÉng padding ƒë·ªÉ tr√°nh n·ªôi dung b·ªã che */
# }

# section.main {
#     flex-grow: 1;
#     overflow-y: auto;
#     padding-bottom: 180px !important; /* TƒÉng padding ƒë·ªÉ tr√°nh n·ªôi dung b·ªã che */
#     margin-bottom: 80px !important; /* Th√™m margin ƒë·ªÉ ƒë·∫£m b·∫£o kho·∫£ng c√°ch */
# }

# /* ƒê·∫£m b·∫£o input hi·ªÉn th·ªã n·ªïi ·ªü cu·ªëi v√† kh√¥ng b·ªã che */
# .stChatInput {
#     position: fixed !important;
#     bottom: 0 !important;
#     left: 0;
#     right: 0;
#     z-index: 99999 !important; /* TƒÉng z-index l√™n cao h∆°n */
#     background: white;
#     padding: 1rem !important;
#     box-shadow: 0 -2px 6px rgba(0,0,0,0.1);
#     max-height: 80px;
# }

# /* Style cho input ƒë·ªÉ d·ªÖ g√µ */
# .stChatInput input {
#     font-size: 1.1rem !important;
#     padding: 15px !important;
#     border-radius: 16px !important;
#     width: 100% !important;
#     box-sizing: border-box !important;
#     background: #fff !important;
#     -webkit-appearance: none !important;
#     border: 1px solid #ccc;
#     position: relative !important;
#     z-index: 100000 !important; /* TƒÉng z-index cho input */
# }

# /* Fix cho Safari iOS */
# @supports (-webkit-touch-callout: none) {
#     .stChatInput {
#         padding-bottom: calc(1rem + env(safe-area-inset-bottom)) !important;
#         bottom: 0 !important;
#     }
    
#     body {
#         padding-bottom: env(safe-area-inset-bottom);
#     }
# }
# </style>
# """
# st.markdown(safari_friendly_css, unsafe_allow_html=True)

# --- Unique session ---
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# --- Model choice ---
if "model_choice" not in st.session_state:
    st.session_state.model_choice = "gemini"

# --- Config ---
FASTAPI_URL = "http://127.0.0.1:8111/chat"

# --- Header ---
st.title("ü§ñ Chatbot T∆∞ V·∫•n B√°n H√†ng")
st.caption("Tr·ª£ l√Ω ·∫£o th√¥ng minh cho c·ª≠a h√†ng c·ªßa b·∫°n")

# --- Model Selection ---
st.sidebar.title("C√†i ƒë·∫∑t")
model_choice = st.sidebar.radio(
    "Ch·ªçn m√¥ h√¨nh AI:",
    ["Gemini", "LM Studio", "OpenAI"],
    index=0,
    help="Ch·ªçn m√¥ h√¨nh AI ƒë·ªÉ x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n"
)

# C·∫≠p nh·∫≠t l·ª±a ch·ªçn m√¥ h√¨nh
if model_choice == "Gemini":
    st.session_state.model_choice = "gemini"
elif model_choice == "LM Studio":
    st.session_state.model_choice = "lmstudio"
else:
    st.session_state.model_choice = "openai"

# Hi·ªÉn th·ªã th√¥ng tin v·ªÅ m√¥ h√¨nh ƒëang s·ª≠ d·ª•ng
model_info = {
    "gemini": "Gemini",
    "lmstudio": "LM Studio",
    "openai": "OpenAI"
}[st.session_state.model_choice]
st.sidebar.info(f"ƒêang s·ª≠ d·ª•ng: {model_info}")

# Hi·ªÉn th·ªã tr·∫°ng th√°i k·∫øt n·ªëi
if st.session_state.model_choice == "lmstudio":
    try:
        # L·∫•y URL t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c s·ª≠ d·ª•ng gi√° tr·ªã m·∫∑c ƒë·ªãnh
        lmstudio_url = os.getenv("LMSTUDIO_API_URL")
        response = requests.get(f"{lmstudio_url}/v1/models", timeout=2)
        if response.status_code == 200:
            st.sidebar.success(f"‚úÖ LM Studio ƒë√£ k·∫øt n·ªëi t·∫°i {lmstudio_url}")
        else:
            st.sidebar.error("‚ùå LM Studio kh√¥ng ph·∫£n h·ªìi")
    except Exception as e:
        st.sidebar.error(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn LM Studio: {str(e)}")
elif st.session_state.model_choice == "openai":
    try:
        import openai
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.sidebar.error("‚ùå Thi·∫øu OPENAI_API_KEY trong .env")
        else:
            client = openai.OpenAI(api_key=api_key)
            # Th·ª≠ g·ªçi models.list ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi
            models = client.models.list()
            st.sidebar.success("‚úÖ OpenAI API key h·ª£p l·ªá v√† k·∫øt n·ªëi th√†nh c√¥ng")
    except Exception as e:
        st.sidebar.error(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn OpenAI: {str(e)}")

# --- Chat history ---
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ch√†o anh/ch·ªã, em c√≥ th·ªÉ gi√∫p g√¨ cho anh/ch·ªã kh√¥ng ·∫°?"}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Chat input handler ---
if prompt := st.chat_input("B·∫°n c·∫ßn t√¨m s·∫£n ph·∫©m n√†o?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        model_name = "Gemini" if st.session_state.model_choice == "gemini" else "LM Studio"
        message_placeholder.markdown(f"C·ª≠a h√†ng ƒëang t√¨m ki·∫øm th√¥ng tin v·ªõi {model_name}... ‚è≥")

        try:
            payload = {
                "message": prompt, 
                "session_id": st.session_state.session_id,
                "model_choice": st.session_state.model_choice
            }
            response = requests.post(FASTAPI_URL, json=payload)
            response.raise_for_status()

            bot_reply = response.json().get("reply", "Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra.")
            message_placeholder.markdown(bot_reply)
            st.session_state.messages.append({"role": "assistant", "content": bot_reply})

        except requests.exceptions.RequestException as e:
            model_name = "Gemini" if st.session_state.model_choice == "gemini" else "LM Studio"
            error_message = f"L·ªói k·∫øt n·ªëi ƒë·∫øn backend khi s·ª≠ d·ª•ng {model_name}: {e}"
            st.error(error_message)
            error_content = f"R·∫•t xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë k·∫øt n·ªëi khi s·ª≠ d·ª•ng {model_name}. Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c ch·ªçn m√¥ h√¨nh kh√°c."
            st.session_state.messages.append({"role": "assistant", "content": error_content})
        except json.JSONDecodeError:
            model_name = "Gemini" if st.session_state.model_choice == "gemini" else "LM Studio"
            st.error(f"L·ªói: Kh√¥ng th·ªÉ gi·∫£i m√£ ph·∫£n h·ªìi t·ª´ server khi s·ª≠ d·ª•ng {model_name}.")
            error_content = f"R·∫•t xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë d·ªØ li·ªáu khi s·ª≠ d·ª•ng {model_name}. Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c ch·ªçn m√¥ h√¨nh kh√°c."
            st.session_state.messages.append({"role": "assistant", "content": error_content})
